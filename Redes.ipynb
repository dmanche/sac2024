{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BiLSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Red LSTM bidireccional\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from tensorflow.keras.layers import LSTM\n",
    "\n",
    "# model\n",
    "model = keras.models.Sequential()\n",
    "model.add(keras.Input(shape=(5754,96)))\n",
    "#model.add(layers.Masking(mask_value=0., input_shape=(5754, 96)))\n",
    "model.add(layers.Bidirectional(LSTM(512, return_sequences=True, activation='tanh')))\n",
    "model.add(layers.Dropout(0.2))\n",
    "model.add(layers.Bidirectional(LSTM(128, return_sequences=True, activation='tanh')))\n",
    "model.add(layers.Dropout(0.2))\n",
    "model.add(layers.Bidirectional(LSTM(64, return_sequences=True, activation='tanh')))\n",
    "model.add(layers.Dense(3, activation = 'softmax'))\n",
    "print(model.summary())\n",
    "\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor='val_accuracy', # Requiere de un conjunto de validación\n",
    "    patience=200,         \n",
    "    verbose=1,           \n",
    "    restore_best_weights=True \n",
    ")\n",
    "\n",
    "model_checkpoint = ModelCheckpoint(\n",
    "    'mejor_modelo_sin_run_mas_metricas.h5',   # Nombre del archivo donde se guardarán los pesos\n",
    "    monitor='val_accuracy', \n",
    "    save_best_only=True,\n",
    "    verbose=1      \n",
    ")\n",
    "\n",
    "loss = keras.losses.CategoricalCrossentropy(from_logits=False)\n",
    "optim = keras.optimizers.Adam(learning_rate=0.001)\n",
    "metrics = [\"accuracy\", 'Precision', 'Recall']\n",
    "\n",
    "model.compile(loss=loss, optimizer=optim, metrics=metrics)\n",
    "\n",
    "batch_size = 16\n",
    "epochs = 200\n",
    "\n",
    "model.fit(X_train, Y_train, batch_size=batch_size, epochs=epochs, verbose=2, callbacks=[model_checkpoint], validation_split=0.2)\n",
    "\n",
    "model.evaluate(X_test, Y_test, batch_size=batch_size, verbose=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM CON 3 CAPAS DENSAS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RED LSTM con 3 capas densas\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from tensorflow.keras.layers import LSTM\n",
    "\n",
    "# model\n",
    "model = keras.models.Sequential()\n",
    "model.add(keras.Input(shape=(5754,96)))\n",
    "#model.add(layers.Masking(mask_value=0., input_shape=(5754, 96)))\n",
    "model.add(LSTM(512, return_sequences=True, activation='tanh'))\n",
    "model.add(layers.Dropout(0.2))\n",
    "model.add(LSTM(512, return_sequences=True, activation='tanh'))\n",
    "model.add(LSTM(512, return_sequences=True, activation='tanh'))\n",
    "model.add(layers.Dropout(0.2))\n",
    "model.add(LSTM(512, return_sequences=True, activation='tanh'))\n",
    "model.add(layers.Dropout(0.2))\n",
    "model.add(LSTM(128, return_sequences=True, activation='tanh'))\n",
    "model.add(LSTM(128, return_sequences=True, activation='tanh'))\n",
    "model.add(layers.Dropout(0.2))\n",
    "model.add(LSTM(128, return_sequences=True, activation='tanh'))\n",
    "model.add(layers.Dropout(0.2))\n",
    "model.add(LSTM(64, return_sequences=True, activation='tanh'))\n",
    "model.add(layers.Dense(32, activation='softmax'))\n",
    "model.add(layers.Dense(16, activation='softmax'))\n",
    "model.add(layers.Dense(3, activation = 'softmax'))\n",
    "print(model.summary())\n",
    "\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor='val_accuracy',   \n",
    "    patience=200,          \n",
    "    verbose=1,            \n",
    "    restore_best_weights=True  \n",
    ")\n",
    "\n",
    "model_checkpoint = ModelCheckpoint(\n",
    "    'mejor_modelo_sin_run_mas_densas.h5',   \n",
    "    monitor='val_accuracy', \n",
    "    save_best_only=True, \n",
    "    verbose=1            \n",
    ")\n",
    "\n",
    "loss = keras.losses.CategoricalCrossentropy(from_logits=False)\n",
    "optim = keras.optimizers.Adam(learning_rate=0.001)\n",
    "metrics = [\"accuracy\", 'Precision', 'Recall']\n",
    "\n",
    "model.compile(loss=loss, optimizer=optim, metrics=metrics)\n",
    "\n",
    "batch_size = 16\n",
    "epochs = 200\n",
    "\n",
    "model.fit(X_train, Y_train, batch_size=batch_size, epochs=epochs, verbose=2, callbacks=[model_checkpoint], validation_split=0.2)\n",
    "\n",
    "model.evaluate(X_test, Y_test, batch_size=batch_size, verbose=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN 1D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RED CNN1D\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv1D, Dropout, AveragePooling1D, BatchNormalization, UpSampling1D, TimeDistributed, Flatten, Dense\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "#model.add(layers.Masking(mask_value=0., input_shape=(5754, 96)))\n",
    "model.add(Conv1D(32, 3, strides=1, activation='relu', padding='same', input_shape=(5754, 96)))\n",
    "model.add(Conv1D(32, 3, strides=1, activation='relu', padding='same'))\n",
    "model.add(AveragePooling1D(pool_size=2, strides=2))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv1D(64, 3, strides=1, activation='relu', padding='same'))\n",
    "model.add(Conv1D(64, 3, strides=1, activation='relu', padding='same'))\n",
    "model.add(AveragePooling1D(pool_size=2, strides=2))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv1D(128, 3, strides=1, activation='relu', padding='same'))\n",
    "model.add(Conv1D(128, 3, strides=1, activation='relu', padding='same'))\n",
    "model.add(AveragePooling1D(pool_size=2, strides=2))\n",
    "model.add(Dropout(0.2)) \n",
    "\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv1D(256, 3, strides=1, activation='relu', padding='same'))\n",
    "model.add(Conv1D(256, 3, strides=1, activation='relu', padding='same'))\n",
    "model.add(AveragePooling1D(pool_size=2, strides=2))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(Dense(3, activation='softmax'))\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy', 'Precision', 'Recall'])\n",
    "\n",
    "model_checkpoint = ModelCheckpoint('mejor_modelo_cnn1d.h5', monitor='val_accuracy', save_best_only=True, verbose=1)\n",
    "\n",
    "model.summary()\n",
    "\n",
    "history = model.fit(X_train, Y_train, validation_split=0.2, epochs=2000, batch_size=16, verbose=2, callbacks=[model_checkpoint])\n",
    "\n",
    "model.evaluate(X_test, Y_test, batch_size=16)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN 2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cambio de señal a imagen\n",
    "import numpy as np\n",
    "\n",
    "num_frames_per_image = 14\n",
    "new_width = 42\n",
    "new_height = 32\n",
    "\n",
    "num_images_per_sequence = X_train_.shape[1] // num_frames_per_image\n",
    "\n",
    "# Reshape de X_train para agrupar cada 10 frames\n",
    "X_reshaped = X_train.reshape(X_train_.shape[0], num_images_per_sequence, num_frames_per_image * X_train_.shape[2])\n",
    "X_reshaped = X_reshaped.reshape(-1, new_width, new_height, 1)  # -1 calcula automáticamente el tamaño necesario\n",
    "\n",
    "# Ajusta las etiquetas Y_train para que coincidan con el nuevo agrupamiento\n",
    "Y_reshaped = Y_train_[:, ::num_frames_per_image, :].reshape(-1, 3)\n",
    "\n",
    "print(X_reshaped.shape)\n",
    "print(Y_reshaped.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RED CNN2D\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from tensorflow.keras.layers import Conv2D, Dropout, AveragePooling2D, BatchNormalization, Flatten, Dense, TimeDistributed\n",
    "\n",
    "model = Sequential([\n",
    "    Conv2D(32, kernel_size=3, strides=(1, 1), activation='relu', padding='same', input_shape=(42, 32, 1)),\n",
    "    Dropout(0.2),\n",
    "    AveragePooling2D(pool_size=2, strides=2, padding='same'),\n",
    "\n",
    "    BatchNormalization(),\n",
    "    Conv2D(64, kernel_size=3, activation='relu', padding='same'),\n",
    "    Dropout(0.2),\n",
    "    AveragePooling2D(pool_size=2, padding='same'),\n",
    "\n",
    "    BatchNormalization(),\n",
    "    Conv2D(128, kernel_size=3, activation='relu', padding='same'),\n",
    "    Dropout(0.2),\n",
    "    AveragePooling2D(pool_size=2, padding='same'),\n",
    "\n",
    "    Conv2D(256, kernel_size=3, activation='relu', padding='same'),\n",
    "    AveragePooling2D(pool_size=2, padding='same'),\n",
    "\n",
    "    Flatten(),\n",
    "    Dense(512, activation='relu'),\n",
    "    Dense(3, activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model.summary()\n",
    "\n",
    "\n",
    "model.summary()\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy', 'Precision', 'Recall'])\n",
    "\n",
    "model_checkpoint = ModelCheckpoint('mejor_modelo.h5', monitor='val_accuracy', save_best_only=True, verbose=1)\n",
    "\n",
    "model.summary()\n",
    "\n",
    "history = model.fit(X_reshaped, Y_reshaped, validation_split=0.2, epochs=200, batch_size=16, verbose=2, callbacks=[model_checkpoint])\n",
    "\n",
    "model.evaluate(X_test, Y_test, batch_size=16)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BiRNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Red recurrente bidireccional\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from tensorflow.keras.layers import SimpleRNN\n",
    "\n",
    "# model\n",
    "model = keras.models.Sequential()\n",
    "model.add(keras.Input(shape=(5754,96)))\n",
    "#model.add(layers.Masking(mask_value=0., input_shape=(5754, 96)))\n",
    "model.add(layers.Bidirectional(SimpleRNN(512, return_sequences=True, activation='tanh')))\n",
    "model.add(layers.Dropout(0.2))\n",
    "model.add(layers.Bidirectional(SimpleRNN(128, return_sequences=True, activation='tanh')))\n",
    "model.add(layers.Dropout(0.2))\n",
    "model.add(layers.Bidirectional(SimpleRNN(64, return_sequences=True, activation='tanh')))\n",
    "model.add(layers.Dense(3, activation = 'softmax'))\n",
    "print(model.summary())\n",
    "\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor='val_accuracy',   \n",
    "    patience=200,     \n",
    "    verbose=1,        \n",
    "    restore_best_weights=True\n",
    ")  \n",
    "\n",
    "model_checkpoint = ModelCheckpoint(\n",
    "    'mejor_modelo_sin_run_mas_metricas.h5',  \n",
    "    monitor='val_accuracy',  \n",
    "    save_best_only=True, \n",
    "    verbose=1           \n",
    ")\n",
    "\n",
    "loss = keras.losses.CategoricalCrossentropy(from_logits=False)\n",
    "optim = keras.optimizers.Adam(learning_rate=0.001)\n",
    "metrics = [\"accuracy\", 'Precision', 'Recall']\n",
    "\n",
    "model.compile(loss=loss, optimizer=optim, metrics=metrics)\n",
    "\n",
    "batch_size = 16\n",
    "epochs = 200\n",
    "\n",
    "model.fit(X_train, Y_train, batch_size=batch_size, epochs=epochs, verbose=2, callbacks=[model_checkpoint], validation_split=0.2)\n",
    "\n",
    "model.evaluate(X_test, Y_test, batch_size=batch_size, verbose=2)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Código para abrir los diccionarios .pkl\n",
    "\n",
    "import pickle as pkl\n",
    "archivo_npz = (\"archivo.pkl\")\n",
    "with open(archivo_npz, 'rb') as f:\n",
    "\tarchivo = pkl.load(f, encoding='latin1')\n",
    "\n",
    "# Código para abrir los diccionarios .npz\n",
    "\n",
    "import numpy as np\n",
    "archivo_npz = np.load(\"archivo.npz\", allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Representar el modelo SMPL utilizando Aitviewer\n",
    "\n",
    "from aitviewer.models.smpl import SMPLLayer\n",
    "from aitviewer.renderables.smpl import SMPLSequence\n",
    "from aitviewer.viewer import Viewer\n",
    "from aitviewer.renderables.spheres import Spheres\n",
    "import numpy as np\n",
    "\n",
    "smpl_layer = SMPLLayer(model_type=\"smpl\", gender=\"male\")\n",
    "\n",
    "# Crear una SMPLSequence estática\n",
    "poses = np.zeros([1, smpl_layer.bm.NUM_BODY_JOINTS * 3]) # 1 frame (ya que es estatico), 72 joints (24 joint x 3 grados de libertad)\n",
    "smpl_seq = SMPLSequence(poses, smpl_layer)\n",
    "\n",
    "viewer = Viewer()\n",
    "viewer.scene.add(smpl_seq)\n",
    "viewer.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Representar una secuencia proveniente de AMASS\n",
    "\n",
    "from aitviewer.models.smpl import SMPLLayer\n",
    "from aitviewer.renderables.smpl import SMPLSequence\n",
    "from aitviewer.viewer import Viewer\n",
    "from aitviewer.configuration import CONFIG as C\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "c = (155 / 255, 87 / 255, 155 / 255, 1)\n",
    "smpl_seq = SMPLSequence.from_amass(\n",
    "        npz_data_path=os.path.join(C.datasets.amass, r\"EyesJapanDataset\\EyesJapanDataset\\shiono\\greeting-04-salute (head)-shiono_poses.npz\"),\n",
    "        fps_out=60.0,\n",
    "        name=\"AMASS_1\", \n",
    "        show_joint_angles=True,\n",
    "        color = c\n",
    "    )\n",
    "\n",
    "viewer = Viewer()\n",
    "viewer.scene.add(smpl_seq)\n",
    "viewer.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Código para convertir archivos .npz a .pkl\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "def process_npz_file(npz_file_path, input_folder, output_folder):\n",
    "    data = np.load(npz_file_path)\n",
    "    extracted_data = {\n",
    "        'gender': data['gender'],\n",
    "        'betas': data['betas'],\n",
    "        'poses': data['poses'],\n",
    "        'frame_rate': data['mocap_framerate'], # Si no funciona prueba con 'mocap_frame_rate'\n",
    "        'trans': data['trans'],\n",
    "    }\n",
    "\n",
    "    relative_path = os.path.relpath(npz_file_path, start=input_folder)\n",
    "\n",
    "    output_folder_path = os.path.join(output_folder, os.path.dirname(relative_path))\n",
    "    os.makedirs(output_folder_path, exist_ok=True)\n",
    "\n",
    "    pkl_file_path = os.path.join(output_folder_path, os.path.basename(npz_file_path).replace('.npz', '_pkl_version.pkl'))\n",
    "\n",
    "    with open(pkl_file_path, 'wb') as pkl_file:\n",
    "        pickle.dump(extracted_data, pkl_file)\n",
    "\n",
    "def process_folder(input_folder, output_folder):\n",
    "    for root, dirs, files in os.walk(input_folder):\n",
    "        for file in files:\n",
    "            if file.endswith('.npz'):\n",
    "                npz_file_path = os.path.join(root, file)\n",
    "                process_npz_file(npz_file_path, input_folder, output_folder)\n",
    "\n",
    "# Ruta de la carpeta principal que contiene las subcarpetas\n",
    "main_folder_path = r'C:\\Users\\danie\\OneDrive\\Escritorio\\TFG\\TFG_entorno\\AMASS_Clasificado\\HDM05\\HDM05'\n",
    "\n",
    "# Carpeta de salida para los archivos pkl\n",
    "output_folder_path = r'c:\\Users\\danie\\OneDrive\\Escritorio\\TFG\\TFG_entorno\\archivospkl\\HDM05\\HDM05'\n",
    "\n",
    "process_folder(main_folder_path, output_folder_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cópdigo de síntesis\n",
    "\n",
    "import glob\n",
    "import os\n",
    "import cv2\n",
    "import sys\n",
    "import numpy as np\n",
    "import chumpy as ch\n",
    "import pickle as pkl\n",
    "\n",
    "# TODO\n",
    "# Añadir las rutas de los archivos SMPL\n",
    "sys.path.append(\"C:\\\\Users\\\\danie\\\\OneDrive\\\\Escritorio\\\\SMPL_python_v.1.1.0\\\\smpl\")\n",
    "sys.path.append(\"C:\\\\Users\\\\danie\\\\OneDrive\\\\Escritorio\\\\SMPL_python_v.1.1.0\\\\smpl\\\\smpl_webuser\")\n",
    "\n",
    "from smpl_webuser.serialization import load_model\n",
    "from smpl_webuser.lbs import global_rigid_transformation\n",
    "\n",
    "#model_path = \"C:\\\\Users\\\\danie\\\\OneDrive\\\\Escritorio\\\\SMPL_python_v.1.1.0\\\\smpl\\\\models\\\\smplh\\\\%s_smplh.pkl\" # Para smplh\n",
    "model_path = \"C:\\\\Users\\\\danie\\\\OneDrive\\\\Escritorio\\\\SMPL_python_v.1.1.0\\\\smpl\\\\models\\\\smpl\\\\%s.pkl\" # Para smpl\n",
    "model_male = load_model(model_path % \"male\")\n",
    "model_female = load_model(model_path % \"female\")\n",
    "\n",
    "Jdirs_male = np.dstack([model_male.J_regressor.dot(model_male.shapedirs[:,:,i]) for i in range(10)])\n",
    "Jdirs_female = np.dstack([model_female.J_regressor.dot(model_male.shapedirs[:,:,i]) for i in range(10)])\n",
    "\n",
    "# TODO\n",
    "# Please modify here to specify which vertices to use\n",
    "VERTEX_IDS = [6740,5763,4560,5213,4361,6060,3021,3498]\n",
    "# rfoot, lfoot, rlowleg, llowleg, rhighleg, lhighleg, back, chest\n",
    "\n",
    "# TODO\n",
    "TARGET_FPS = 60\n",
    "\n",
    "# TODO\n",
    "# Please modify here to specify which SMPL joints to use\n",
    "SMPL_IDS = [1, 2, 3, 4, 5, 6, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]\n",
    "\n",
    "# Extrae la categoría de movimiento del nombre del archivo\n",
    "def extract_movement_category(file_name):\n",
    "    keywords_stand = ['stand', 'neutral', 'rest', 'static', 'wave', 'shake_arm', 'shake_shoulder', 'gesture_etc-05-touch nose']\n",
    "    keywords_walk = ['walk', 'walking','treadmill']\n",
    "    keywords_run = ['run', 'jog', 'jogging', 'running']\n",
    "    keywords_sit = [ 'sit', 'sitting', 'sitdown', 'situp', 'chair']\n",
    "    keywords = [keywords_stand, keywords_walk, keywords_run, keywords_sit]\n",
    "\n",
    "    for keyword_class in keywords:\n",
    "        for keyword in keyword_class:\n",
    "            if keyword in file_name.lower():\n",
    "                return keyword_class[0]\n",
    "            \n",
    "    return 'unknown'\n",
    "\n",
    "# Get orientation and acceleration from list of 4x4 matrices, and vertices\n",
    "def get_ori_accel(A_global_list, vertex, frame_rate):\n",
    "    orientation = []\n",
    "    acceleration = []\n",
    "\n",
    "    for a_global in A_global_list:\n",
    "        ori_left_foot = a_global[10][:3, :3].r\n",
    "        ori_right_foot = a_global[11][:3, :3].r\n",
    "        ori_left_lowleg = a_global[4][:3, :3].r\n",
    "        ori_right_lowleg = a_global[5][:3, :3].r\n",
    "        ori_left_highleg = a_global[1][:3, :3].r\n",
    "        ori_right_highleg = a_global[2][:3, :3].r\n",
    "        ori_chest = a_global[9][:3, :3].r\n",
    "        ori_root = a_global[3][:3, :3].r\n",
    "\n",
    "        ori_tmp = []\n",
    "        ori_tmp.append(ori_left_foot)\n",
    "        ori_tmp.append(ori_right_foot)\n",
    "        ori_tmp.append(ori_left_lowleg)\n",
    "        ori_tmp.append(ori_right_lowleg)\n",
    "        ori_tmp.append(ori_left_highleg)\n",
    "        ori_tmp.append(ori_right_highleg)\n",
    "        ori_tmp.append(ori_chest)\n",
    "        ori_tmp.append(ori_root)\n",
    "        \n",
    "        orientation.append(np.array(ori_tmp))\n",
    "\n",
    "    time_interval = 1.0 / frame_rate\n",
    "    total_number = len(A_global_list)\n",
    "    for idx in range(1, total_number-1):\n",
    "        vertex_0 = vertex[idx-1].astype(float) # 6*3\n",
    "        vertex_1 = vertex[idx].astype(float)\n",
    "        vertex_2 = vertex[idx+1].astype(float)\n",
    "        accel_tmp = (vertex_2 + vertex_0 - 2*vertex_1) / (time_interval*time_interval)\n",
    "\n",
    "        acceleration.append(accel_tmp)\n",
    "\n",
    "    return orientation[1:-1], acceleration\n",
    "\n",
    "\n",
    "def compute_imu_data(gender, betas, poses, frame_rate):\n",
    "    if gender == 'male':\n",
    "        Jdirs = Jdirs_male\n",
    "        model = model_male\n",
    "    else:\n",
    "        Jdirs = Jdirs_female\n",
    "        model = model_female\n",
    "\n",
    "    betas[:] = 0\n",
    "    J_onbetas = ch.array(Jdirs).dot(betas) + model.J_regressor.dot(model.v_template.r)\n",
    "\n",
    "    A_global_list = []\n",
    "    print( 'Longitud del archivo: %d' % (len(poses)/1) )\n",
    "    for idx, p in enumerate(poses):\n",
    "        if len(p) != 72:\n",
    "            raise ValueError(\"La longitud de la pose debe ser 72.\")\n",
    "        (_, A_global) = global_rigid_transformation(p, J_onbetas, model.kintree_table, xp=ch)\n",
    "        A_global_list.append(A_global)\n",
    "    \n",
    "    vertex = []\n",
    "    for idx, p in enumerate(poses):\n",
    "        model.pose[:] = p\n",
    "        model.betas[:] = 0\n",
    "        model.betas[:10] = betas\n",
    "        tmp =  model.r[VERTEX_IDS]\n",
    "        vertex.append(tmp) # 6*3\n",
    "            \n",
    "\n",
    "    orientation, acceleration = get_ori_accel(A_global_list, vertex, frame_rate)\n",
    "\n",
    "    return orientation, acceleration\n",
    "\n",
    "\n",
    "def findNearest(t, t_list):\n",
    "    list_tmp = np.array(t_list) - t\n",
    "    list_tmp = np.abs(list_tmp)\n",
    "    index = np.argsort(list_tmp)[:2]\n",
    "    return index\n",
    "\t\n",
    "\n",
    "# Turn MoCap data into 60FPS\n",
    "def interpolation_integer(poses_ori, fps):\n",
    "    poses = []\n",
    "    n_tmp = int(fps / TARGET_FPS)\n",
    "    poses_ori = poses_ori[::n_tmp]\n",
    "    \n",
    "    for t in poses_ori:\n",
    "        poses.append(t)\n",
    "\n",
    "    return poses\n",
    "\n",
    "def interpolation(poses_ori, fps):\n",
    "    poses = []\n",
    "    total_time = len(poses_ori) / fps\n",
    "    times_ori = np.arange(0, total_time, 1.0 / fps)\n",
    "    times = np.arange(0, total_time, 1.0 / TARGET_FPS)\n",
    "    \n",
    "    for t in times:\n",
    "        index = findNearest(t, times_ori)\n",
    "        a = poses_ori[index[0]]\n",
    "        t_a = times_ori[index[0]]\n",
    "        b = poses_ori[index[1]]\n",
    "        t_b = times_ori[index[1]]\n",
    "\n",
    "        if t_a == t: \n",
    "            tmp_pose = a\n",
    "        elif t_b == t:\n",
    "            tmp_pose = b\n",
    "        else:\n",
    "            tmp_pose = a + (b-a)*((t_b-t)/(t_b-t_a)) \n",
    "        poses.append(tmp_pose)\n",
    "\n",
    "    return poses\n",
    "\n",
    "\n",
    "# Extract pose parameter from pkl_path, save to res_path\n",
    "def generate_data(pkl_path, res_path):\n",
    "    if os.path.exists(res_path):\n",
    "        return\n",
    "\n",
    "    with open(pkl_path, 'rb') as fin:\n",
    "        data_in = pkl.load(fin, encoding='latin1')\n",
    "    \n",
    "    data_out = {}\n",
    "    data_out['gender'] = data_in['gender']\n",
    "    data_out['betas'] = np.array(data_in['betas'][:10])\n",
    "    data_in_poses = data_in['poses'][:, :72] # De esta forma nos quedamos solo con los 72 primeros parámetros, corespondientes al modelo SMPL, en lugar de usar el modelo SMPLX (con el cual el codigo no seria compatible)\n",
    "\n",
    "    # In case the original frame rates (eg 40FPS) are different from target rates (60FPS) \n",
    "    fps_ori = data_in['frame_rate']\n",
    "    if (fps_ori % TARGET_FPS) == 0:\n",
    "        data_out['poses'] = interpolation_integer(data_in_poses, fps_ori)\n",
    "    else:\n",
    "        data_out['poses'] = interpolation(data_in_poses, fps_ori)\n",
    "\n",
    "    data_out['ori'], data_out['acc'] = compute_imu_data(data_out['gender'], data_out['betas'], data_out['poses'], TARGET_FPS)\n",
    "    \n",
    "    data_out['poses'] = data_out['poses'][1:-1]\n",
    "\n",
    "    for fdx in range(0, len(data_out['poses'])):\n",
    "        pose_tmp = []#np.zeros(0)\n",
    "        for jdx in SMPL_IDS:\n",
    "            tmp = data_out['poses'][fdx][jdx*3:(jdx+1)*3]\n",
    "            tmp = cv2.Rodrigues(tmp)[0].flatten().tolist()\n",
    "            pose_tmp = pose_tmp + tmp\n",
    "\n",
    "        data_out['poses'][fdx] = []\n",
    "        data_out['poses'][fdx] = pose_tmp\n",
    "\n",
    "    data_out_ = {}\n",
    "    data_out_['ori'] = data_out['ori']\n",
    "    data_out_['acc'] = data_out['acc']\n",
    "    file_name = os.path.basename(pkl_path)\n",
    "    data_out_['gt'] = extract_movement_category(file_name)\n",
    "\n",
    "    with open(res_path, 'wb') as fout:\n",
    "            pkl.dump(data_out_, fout)\n",
    "    print( pkl_path )\n",
    "    print( res_path )\n",
    "    print( len(data_out['acc']) )\n",
    "    print( '' )\n",
    "\n",
    "\n",
    "def get_relative_path(pkl_file_path, input_folder):\n",
    "    return os.path.relpath(pkl_file_path, start=input_folder)\n",
    "\n",
    "def generate_synthetic_data(pkl_file_path, output_folder):\n",
    "    print(f\"Procesando archivo: {pkl_file_path}\")\n",
    "    \n",
    "    relative_path = get_relative_path(pkl_file_path, pkl_folder_path)\n",
    "\n",
    "    output_folder_path = os.path.join(output_folder, os.path.dirname(relative_path))\n",
    "    os.makedirs(output_folder_path, exist_ok=True)\n",
    "\n",
    "    res_data_path = os.path.join(output_folder_path, os.path.basename(pkl_file_path).replace('.pkl', '_synthetic.pkl'))\n",
    "\n",
    "    generate_data(pkl_file_path, res_data_path)\n",
    "\n",
    "def process_pkl_folder(input_folder, output_folder):\n",
    "    # Puede que sea necesario que se cambie el patrón de búsqueda de archivos pkl, dependiendo de la estructura de la carpeta. En mi caso, los archivos pkl estaban en subcarpetas de 4 niveles de profundidad.\n",
    "    print(os.path.join(input_folder, '*.pkl'))\n",
    "    for pkl_file_path in glob.glob(os.path.join(input_folder, '*/*/*/*.pkl'), recursive=True):\n",
    "        print(f\"Procesando archivo: {pkl_file_path}\")\n",
    "        generate_synthetic_data(pkl_file_path, output_folder)\n",
    "\n",
    "# Ruta de la carpeta principal que contiene los archivos pkl\n",
    "pkl_folder_path = 'C:\\\\Users\\\\danie\\\\OneDrive\\\\Escritorio\\\\TFG\\\\TFG_entorno\\\\archivospkl'\n",
    "\n",
    "# Carpeta de salida para los archivos sintéticos pkl\n",
    "output_folder_path = 'C:\\\\Users\\\\danie\\\\OneDrive\\\\Escritorio\\\\TFG\\\\TFG_entorno\\\\datos_sinteticos_amass_definitivos'\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    process_pkl_folder(pkl_folder_path, output_folder_path)\n",
    "    \n",
    "\n",
    "\"\"\"\n",
    "@article{DIP:SIGGRAPHAsia:2018,\n",
    "\ttitle = {Deep Inertial Poser: Learning to Reconstruct Human Pose from Sparse Inertial Measurements in Real Time},\n",
    "    \tauthor = {Huang, Yinghao and Kaufmann, Manuel and Aksan, Emre and Black, Michael J. and Hilliges, Otmar and Pons-Moll, Gerard},\n",
    "    \tjournal = {ACM Transactions on Graphics, (Proc. SIGGRAPH Asia)},\n",
    "    \tvolume = {37},\n",
    "    \tpages = {185:1-185:15},\n",
    "    \tpublisher = {ACM},\n",
    "    \tmonth = nov,\n",
    "    \tyear = {2018},\n",
    "    \tnote = {First two authors contributed equally},\n",
    "    \tmonth_numeric = {11}\n",
    "}\n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
